# -*- coding: utf-8 -*-
"""bondpredictionstreamlit

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XD9iD2w8nTiD5Qh3b6uu9q-ldJjfXaMA
"""

MODEL_DIR = ''
MODEL_NAME = 'bond_customer_prediction_v5.json' # Make sure this EXACTLY matches your saved model file
ENCODER_NAME = 'onehot_encoder.joblib'

MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME)
ENCODER_PATH = os.path.join(MODEL_DIR, ENCODER_NAME)

ALL_BOND_SECTORS = [
    'AUTO', 'COMM', 'CONS', 'ENERG', 'FIN', 'FOOD', 'PAPER',
    'PROP', 'STEEL', 'TOURISM', 'TRANS'
] # Add other sectors if your training data had them
ALL_BOND_ISSUER_TYPES = ['GBS'] # GBS is in your list, others if seen in training
ALL_BOND_GRADE_TYPES = ['Investment_Grade', 'Non_Investment_Grade']
ALL_BOND_SECURITY_TYPES = ['Secured', 'Unsecured']
ALL_BOND_CREDIT_RATINGS = ['0', 'A_', 'B', 'BB', 'BB+', 'BB_', 'BBB', 'BBB+', 'BBB_', 'Non_rated']

@st.cache_resource # Cache the model and encoder loading to avoid reloading on every rerun
def load_model_and_encoder():
    try:
        # Check if the MODEL_DIR exists first (unless MODEL_DIR is empty string or '.')
        if MODEL_DIR and not os.path.exists(MODEL_DIR):
            st.error(f"Error: Directory '{MODEL_DIR}' not found.")
            st.info("If your files are directly in the repo root, ensure MODEL_DIR = '' or MODEL_DIR = '.'")
            st.stop()

        # Load the trained XGBoost model
        model = xgb.XGBClassifier()
        model.load_model(MODEL_PATH)
        st.success(f"Successfully loaded XGBoost model from '{MODEL_PATH}'")

        # Load the fitted OneHotEncoder
        encoder = joblib.load(ENCODER_PATH)
        st.success(f"Successfully loaded OneHotEncoder from '{ENCODER_PATH}'")

        # IMPORTANT: Retrieve the feature names the model was trained on
        # This list MUST EXACTLY MATCH the columns of your X_train
        # AFTER One-Hot Encoding but BEFORE any feature engineering.
        if hasattr(model, 'feature_names_in_') and model.feature_names_in_ is not None:
             trained_feature_names = list(model.feature_names_in_)
        else:
            st.warning("`model.feature_names_in_` not found or empty. Using a hardcoded feature list.")
            st.warning("PLEASE ENSURE this hardcoded list EXACTLY MATCHES your training features AFTER One-Hot Encoding and WITHOUT Feature Engineering.")
            trained_feature_names = ['customer_num_bond_transactions', 'customer_aum', 'customer_total_bond_investment', 'bond_transaction_value', 'bond_term_years',
                                     'customer_avg_bond_transaction_size', 'bond_credit_rating_0', 'bond_credit_rating_A_', 'bond_credit_rating_B', 'bond_credit_rating_BB',
                                     'bond_credit_rating_BB+', 'bond_credit_rating_BB_', 'bond_credit_rating_BBB', 'bond_credit_rating_BBB+', 'bond_credit_rating_BBB_',
                                     'bond_credit_rating_Non_rated', 'bond_sector_AUTO', 'bond_sector_COMM', 'bond_sector_CONS', 'bond_sector_ENERG', 'bond_sector_FIN',
                                     'bond_sector_FOOD', 'bond_sector_PAPER', 'bond_sector_PROP', 'bond_sector_STEEL', 'bond_sector_TOURISM', 'bond_sector_TRANS',
                                     'bond_security_type_Secured', 'bond_security_type_Unsecured', 'bond_grade_type_Investment_Grade', 'bond_grade_type_Non_Investment_Grade',
                                     'bond_issuer_type_GBS'
            ]
        return model, encoder, trained_feature_names
    except FileNotFoundError as e:
        st.error(f"File not found: {e}. Please ensure the model and encoder files are in the '{MODEL_DIR}' directory.")
        st.info("If your files are in the same directory as this script, ensure MODEL_DIR is set to '' or '.'")
        st.info("If you are running from GitHub, make sure you have cloned the repository (not just downloaded individual files) and that the 'models' folder exists and contains the necessary files.")
        st.stop()
    except Exception as e:
        st.error(f"An unexpected error occurred while loading: {e}")
        st.stop()
def prepare_raw_input_data(df_to_prepare):
    df_copy = df_to_prepare.copy()

    # Ensure core numerical features are present and filled with sensible defaults
    numerical_cols = [
        'customer_num_bond_transactions', 'customer_aum', 'customer_total_bond_investment',
        'bond_transaction_value', 'bond_term_years', 'customer_avg_bond_transaction_size'
    ]
    for col in numerical_cols:
        if col not in df_copy.columns:
            df_copy[col] = 0.0 # Default numerical to 0 or a median/mean from training
        df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce').fillna(0.0) # Ensure numeric, fill NaNs

    # Ensure categorical features are present and filled with a default (e.g., 'Non_rated', 'GBS', 'Unknown')
    # These strings will be One-Hot Encoded later.
    categorical_cols_raw = [
        'bond_credit_rating', 'bond_issuer_type', 'bond_grade_type',
        'bond_sector', 'bond_security_type'
    ]
    for col in categorical_cols_raw:
        if col not in df_copy.columns:
            # Provide a default category that the OHE knows or handles (e.g., 'Non_rated', 'GBS', 'Unknown')
            if col == 'bond_credit_rating':
                df_copy[col] = 'Non_rated'
            elif col == 'bond_issuer_type':
                df_copy[col] = 'GBS' # Default to GBS if not present
            elif col == 'bond_grade_type':
                df_copy[col] = 'Investment Grade'
            elif col == 'bond_sector':
                df_copy[col] = 'FIN' # Default sector
            elif col == 'bond_security_type':
                df_copy[col] = 'Secured'
            else:
                df_copy[col] = 'Unknown' # Generic default for other categoricals
        df_copy[col] = df_copy[col].astype(str).fillna('Unknown') # Ensure string type, fill any NaN with 'Unknown'

    # Handle other columns that were in raw input but are dropped (e.g., IDs, dates)
    # These are needed for the `df_copy.get` if the CSV has them, but are not
    # part of the final feature set, so they are not critical to fill if missing
    # in new data, as they'll be dropped.
    for col in ['bond_issued_date', 'bond_maturity_date', 'Transaction_Date', 'Synthetic_Customer_ID', 'bond_symbol_primary', 'Gender', 'bond_coupon_rate_str', 'bond_symbol_secondary']:
        if col not in df_copy.columns:
            if 'date' in col:
                df_copy[col] = pd.to_datetime('2022-01-01')
            else:
                df_copy[col] = 'N/A' # Placeholder for other non-feature columns
        else:
            if 'date' in col:
                df_copy[col] = pd.to_datetime(df_copy[col], errors='coerce')


    return df_copy


# --- Preprocessing Function for New Data (applies OHE and alignment) ---
def preprocess_new_data(df_new_raw, encoder, trained_feature_names):
    """
    Applies initial feature preparation, then performs One-Hot Encoding and final feature alignment.
    """
    df_prepared_input = prepare_raw_input_data(df_new_raw)

    # 1. Define columns to drop BEFORE One-Hot Encoding and final feature selection
    # These are typically IDs or original date/string columns that are NOT used as OHE outputs
    columns_to_drop_after_prepare = [
        'Synthetic_Customer_ID', 'bond_symbol_primary',
        'bond_issued_date', 'bond_maturity_date',
        'Transaction_Date',
        'Gender', # Drop if not in final features
        'bond_coupon_rate_str', # Drop if not in final features
        'bond_symbol_secondary', # Drop if not in final features
    ]
    # Drop specified columns, keeping only the raw features for OHE and numerical features
    df_for_ohe_and_numerical = df_prepared_input.drop(columns=columns_to_drop_after_prepare, errors='ignore').copy()

    # 2. Identify categorical columns for One-Hot Encoding
    # These must be the raw categorical columns that the encoder was fitted on during training
    # Based on your provided trained_feature_names, these are:
    categorical_cols_to_ohe = [
        'bond_credit_rating', 'bond_sector', 'bond_security_type',
        'bond_grade_type', 'bond_issuer_type'
    ]

    # Separate numerical and categorical parts
    # Ensure categorical columns are actual categories for OHE.
    # We must ensure all categories seen during training are known to the encoder,
    # or handle_unknown='ignore' will just output zeros for unseen ones.
    for col in categorical_cols_to_ohe:
        if col in df_for_ohe_and_numerical.columns:
            df_for_ohe_and_numerical[col] = df_for_ohe_and_numerical[col].astype(str)
        else:
            # If a categorical column is missing from input but expected by OHE, create it with a default
            if col == 'bond_credit_rating': df_for_ohe_and_numerical[col] = 'Non_rated'
            elif col == 'bond_issuer_type': df_for_ohe_and_numerical[col] = 'GBS'
            elif col == 'bond_grade_type': df_for_ohe_and_numerical[col] = 'Investment Grade'
            elif col == 'bond_sector': df_for_ohe_and_numerical[col] = 'FIN'
            elif col == 'bond_security_type': df_for_ohe_and_numerical[col] = 'Secured'
            else: df_for_ohe_and_numerical[col] = 'Unknown'
            df_for_ohe_and_numerical[col] = df_for_ohe_and_numerical[col].astype(str) # Ensure it's string for OHE

    df_categorical_part = df_for_ohe_and_numerical[categorical_cols_to_ohe]
    df_numerical_part = df_for_ohe_and_numerical.drop(columns=categorical_cols_to_ohe)

    # Transform categorical features using the loaded encoder
    X_encoded = encoder.transform(df_categorical_part)
    X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(categorical_cols_to_ohe), index=df_for_ohe_and_numerical.index)

    # Concatenate numerical and encoded parts
    df_processed = pd.concat([df_numerical_part, X_encoded_df], axis=1)

    # 3. Ensure all column names are valid for XGBoost BEFORE reindexing
    df_processed.columns = [col.replace('[', '_').replace(']', '_').replace('<', '_').replace(' ', '_').replace('-', '_').replace('__', '_') for col in df_processed.columns]

    # 4. Ensure feature consistency with the training data (trained_feature_names)
    # Add missing columns (features present in training but not in this new data), filled with zeros
    missing_in_new_data = list(set(trained_feature_names) - set(df_processed.columns))
    for col in missing_in_new_data:
        df_processed[col] = 0.0 # Use float 0.0 for consistency with numerical features

    # Drop extra columns (features present in new data but not in training data)
    extra_in_new_data = list(set(df_processed.columns) - set(trained_feature_names))
    if extra_in_new_data:
        df_processed = df_processed.drop(columns=extra_in_new_data)

    # Ensure the order of columns is identical to training data
    # This is critical for model inference
    df_processed = df_processed[trained_feature_names]

    # Final check: Ensure all columns are numeric
    for col in df_processed.columns:
        if df_processed[col].dtype == 'object':
            df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce').fillna(0)

    return df_processed


# --- Streamlit App Layout ---
st.set_page_config(layout="wide")
st.title("ðŸ’° Bond Purchase Propensity Predictor (Manual & CSV Batch Input)")
st.write("Predict the likelihood of a customer purchasing a specific bond using a model trained on your available data.")

# --- Load Model and Encoder (Cached) ---
model, encoder, trained_feature_names = load_model_and_encoder()

# --- Input Options: Manual vs. CSV Upload ---
st.sidebar.header("Prediction Mode")
prediction_mode = st.sidebar.radio("Choose Input Method:", ("Manual Input", "Upload CSV File"))

# --- Manual Input Section ---
if prediction_mode == "Manual Input":
    st.header("Enter Customer and Bond Information for Prediction")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Customer Numerical Features")
        customer_aum_input = st.slider("Customer AUM ($)", 10000.0, 10000000.0, 500000.0, 10000.0)
        customer_num_bond_transactions_input = st.number_input("Customer Past Bond Transactions", min_value=0, value=0)
        customer_total_bond_investment_input = st.number_input("Customer Total Bond Investment ($)", min_value=0.0, value=0.0, format="%.2f")
        customer_avg_bond_transaction_size_input = st.number_input("Customer Avg Bond Transaction Size ($)", min_value=0.0, value=0.0, format="%.2f")

        st.subheader("Bond Numerical Features")
        bond_transaction_value_input = st.number_input("Bond Transaction Value ($)", min_value=0.0, value=100000.0, format="%.2f")
        bond_term_years_input = st.slider("Bond Term (Years)", 1, 50, 10)


    with col2:
        st.subheader("Bond Categorical Features")
        bond_credit_rating_input = st.selectbox("Bond Credit Rating", credit_rating_map_keys, index=credit_rating_map_keys.index('AAA'))
        bond_issuer_type_input = st.selectbox("Bond Issuer Type", ['GBS', 'CORP', 'MUNI', 'OTHER']) # Expanded for more general input
        bond_grade_type_input = st.selectbox("Bond Grade Type", ALL_BOND_GRADE_TYPES)
        bond_sector_input = st.selectbox("Bond Sector", ALL_BOND_SECTORS)
        bond_security_type_input = st.selectbox("Bond Security Type", ALL_BOND_SECURITY_TYPES)


    predict_button = st.button("Predict Bond Purchase Propensity")

    if predict_button:
        # Create a DataFrame for the single manual input
        manual_input_data = pd.DataFrame([{
            'customer_num_bond_transactions': customer_num_bond_transactions_input,
            'customer_aum': customer_aum_input,
            'customer_total_bond_investment': customer_total_bond_investment_input,
            'bond_transaction_value': bond_transaction_value_input,
            'bond_term_years': bond_term_years_input,
            'customer_avg_bond_transaction_size': customer_avg_bond_transaction_size_input,
            'bond_credit_rating': bond_credit_rating_input, # String for OHE
            'bond_issuer_type': bond_issuer_type_input,
            'bond_grade_type': bond_grade_type_input,
            'bond_sector': bond_sector_input,
            'bond_security_type': bond_security_type_input,

            # Placeholder for columns that prepare_raw_input_data expects but are dropped later
            'bond_issued_date': pd.to_datetime('2022-01-01'),
            'bond_maturity_date': pd.to_datetime('2032-01-01'),
            'Transaction_Date': pd.to_datetime('now'),
            'Synthetic_Customer_ID': 'manual_customer',
            'bond_symbol_primary': 'manual_bond',
            'Gender': 'N/A', # Added if Gender might ever be in input
            'bond_coupon_rate_str': 'N/A', # Added if it might ever be in input
            'bond_symbol_secondary': 'N/A' # Added if it might ever be in input
        }])

        st.write("Raw Manual Input:")
        st.dataframe(manual_input_data)

        with st.spinner("Preprocessing and Predicting..."):
            # Preprocess the manual input data
            preprocessed_manual_data = preprocess_new_data(manual_input_data, encoder, trained_feature_names)

            st.write("Preprocessed Data for Prediction (first 5 columns):")
            st.dataframe(preprocessed_manual_data.head())
            st.write(f"Shape of preprocessed data: {preprocessed_manual_data.shape}")

            # Make prediction
            try:
                prediction_proba = model.predict_proba(preprocessed_manual_data)[:, 1][0] # Get probability for class 1
                st.subheader("Prediction Result:")
                st.info(f"Predicted Probability of Bond Purchase: **{prediction_proba:.2%}**")

                if prediction_proba >= 0.5: # Example threshold
                    st.success("This customer has a high likelihood of purchasing the bond.")
                else:
                    st.warning("This customer has a lower likelihood of purchasing the bond.")
            except Exception as e:
                st.error(f"Error during prediction: {e}")
                st.info("Please check if the preprocessed input data matches the model's expected features. Refer to console for details.")
                # st.write(f"Expected features (model.feature_names_in_): {model.feature_names_in_}") # This might be None if model not trained with feature_names_in_ set
                st.write(f"Received features (preprocessed_manual_data.columns): {preprocessed_manual_data.columns.tolist()}")


# --- CSV Upload Section ---
elif prediction_mode == "Upload CSV File":
    st.header("Upload CSV File for Batch Prediction")
    st.write("Upload a CSV file containing multiple rows of customer and bond data for bulk prediction.")
    st.info("""The CSV should contain the following raw columns (case-sensitive, order doesn't matter):
    - **Numerical:** `customer_num_bond_transactions`, `customer_aum`, `customer_total_bond_investment`,
      `bond_transaction_value`, `bond_term_years`, `customer_avg_bond_transaction_size`
    - **Categorical:** `bond_credit_rating`, `bond_issuer_type`, `bond_grade_type`, `bond_sector`, `bond_security_type`
    - *(Optional, for internal function robustness, but dropped for model: `bond_issued_date`, `bond_maturity_date`, `Transaction_Date`, `Synthetic_Customer_ID`, `bond_symbol_primary`, `Gender`, `bond_coupon_rate_str`, `bond_symbol_secondary`)*""")

    uploaded_file = st.file_uploader("Choose a CSV file", type="csv")

    if uploaded_file is not None:
        try:
            input_df_raw = pd.read_csv(uploaded_file)
            st.subheader("Uploaded Data Preview (First 5 Rows):")
            st.dataframe(input_df_raw.head())

            predict_batch_button = st.button("Predict for Uploaded File")

            if predict_batch_button:
                with st.spinner("Processing and Predicting for all rows..."):
                    # Preprocess the entire DataFrame
                    preprocessed_batch_data = preprocess_new_data(input_df_raw.copy(), encoder, trained_feature_names)

                    # Make batch predictions
                    batch_prediction_probas = model.predict_proba(preprocessed_batch_data)[:, 1]

                    # Add predictions to the original input DataFrame
                    # Using .loc to avoid SettingWithCopyWarning
                    input_df_raw.loc[:, 'Predicted_Propensity'] = batch_prediction_probas
                    input_df_raw.loc[:, 'Predicted_Purchase'] = (batch_prediction_probas >= 0.5).astype(int)

                    st.subheader("Prediction Results (First 10 Rows):")
                    st.dataframe(input_df_raw.head(10))

                    # Provide download link
                    csv_output = input_df_raw.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="Download Predictions as CSV",
                        data=csv_output,
                        file_name="bond_predictions.csv",
                        mime="text/csv",
                    )
                    st.success("Batch predictions complete! Download the CSV above.")

        except Exception as e:
            st.error(f"Error processing uploaded file: {e}")
            st.info("Please ensure your CSV file is correctly formatted and contains the expected columns for feature engineering.")


st.markdown("---")
st.markdown("---")
st.markdown("To train the model and generate the `bond_customer_prediction_v5.json` and `onehot_encoder.joblib` files, please refer to your training notebook.")