# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z81azUImwAxDXfEsBbFTDM09dC2gzqtQ
"""

import streamlit as st
import pandas as pd
import numpy as np
import xgboost as xgb
import os
import joblib # For saving/loading scikit-learn objects like OneHotEncoder

# --- Configuration & Paths ---
# IMPORTANT: This section defines WHERE your Streamlit app EXPECTS to find
# your saved model and encoder files on the local filesystem of the deployment.

# If your model and encoder files are directly in the SAME directory
# as this Streamlit app script (e.g., 'bond_predictor_app.py')
# AND you push them directly to the main GitHub repo folder:
MODEL_DIR = '' # Set to an empty string to look in the current directory (repo root)
# OR
# MODEL_DIR = '.' # This also works for the current directory

# If you prefer to put them in a subdirectory named 'models' in your repo:
# MODEL_DIR = 'models'

# If you are running this in Google Colab AND storing models in Drive:
# from google.colab import drive
# drive.mount('/content/drive')
# MODEL_DIR = '/content/drive/My Drive/Colab Notebooks/models' # Example: full path in Drive


MODEL_NAME = 'xgboost_bond_group_model.json' # Make sure this EXACTLY matches your saved model file
ENCODER_NAME = 'onehot_encoder.joblib' # Make sure this EXACTLY matches your saved encoder file

# Full paths for the model and encoder files
MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME)
ENCODER_PATH = os.path.join(MODEL_DIR, ENCODER_NAME)

# --- Removed Helper Function: Feature Engineering ---
# Since the model was NOT trained on feature-engineered data,
# this function is no longer needed in the prediction pipeline.
# If you ever decide to train a new model WITH feature engineering,
# you would re-introduce this function and its call.


# --- Load Model and Encoder ---
@st.cache_resource # Cache the model and encoder loading to avoid reloading on every rerun
def load_model_and_encoder():
    try:
        # Check if the MODEL_DIR exists first (unless MODEL_DIR is empty string or '.')
        if MODEL_DIR and not os.path.exists(MODEL_DIR):
            st.error(f"Error: Directory '{MODEL_DIR}' not found.")
            st.info("If your files are directly in the repo root, ensure MODEL_DIR = '' or MODEL_DIR = '.'")
            st.stop()

        # Load the trained XGBoost model
        model = xgb.XGBClassifier()
        model.load_model(MODEL_PATH)
        st.success(f"Successfully loaded XGBoost model from '{MODEL_PATH}'")

        # Load the fitted OneHotEncoder
        encoder = joblib.load(ENCODER_PATH)
        st.success(f"Successfully loaded OneHotEncoder from '{ENCODER_PATH}'")

        # IMPORTANT: Retrieve the feature names the model was trained on
        # This list MUST EXACTLY MATCH the columns of your X_train
        # AFTER One-Hot Encoding but BEFORE any feature engineering.
        if hasattr(model, 'feature_names_in_') and model.feature_names_in_ is not None:
             trained_feature_names = list(model.feature_names_in_)
        else:
            st.warning("`model.feature_names_in_` not found or empty. Using a hardcoded feature list.")
            st.warning("PLEASE ENSURE this hardcoded list EXACTLY MATCHES your training features AFTER One-Hot Encoding and WITHOUT Feature Engineering.")
            trained_feature_names = [
                'Age', 'Income', 'Existing_Equity_Holdings', 'Existing_Bond_Holdings', 'Total_AUM',
                'Num_Other_Products', 'Last_Investment_Days_Ago', 'Bond_Coupon_Rate',
                'Bond_Maturity_Years', 'Bond_Min_Investment', 'Debt_to_Income_Ratio',
                'Portfolio_Fixed_Income_Percent',
                # One-hot encoded features from ORIGINAL categorical columns
                'Education_Bachelors', 'Education_High School', 'Education_Masters', 'Education_PhD',
                'Risk_Tolerance_Aggressive', 'Risk_Tolerance_Conservative', 'Risk_Tolerance_Moderate',
                'Online_Platform_Usage_Freq_High', 'Online_Platform_Usage_Freq_Low', 'Online_Platform_Usage_Freq_Medium',
                'Bond_Credit_Rating_A', 'Bond_Credit_Rating_AA', 'Bond_Credit_Rating_AAA'
                # Note: 'Age_Bin' and other engineered features are REMOVED here
            ]
            # To get the exact list from your training notebook if you ran without FE:
            # print(X_train_after_ohe_before_fe.columns.tolist())


        return model, encoder, trained_feature_names
    except FileNotFoundError as e:
        st.error(f"File not found: {e}. Please ensure the model and encoder files are in the '{MODEL_DIR}' directory.")
        st.info("If your files are in the same directory as this script, ensure MODEL_DIR is set to '' or '.'")
        st.info("If you are running from GitHub, make sure you have cloned the repository (not just downloaded individual files) and that the 'models' folder exists and contains the necessary files.")
        st.stop()
    except Exception as e:
        st.error(f"An unexpected error occurred while loading: {e}")
        st.stop()


# --- Preprocessing Function for New Data ---
def preprocess_for_prediction(df_raw_input, encoder, trained_feature_names):
    """
    Applies the same preprocessing (One-Hot Encoding) as used during training
    to a new raw input DataFrame. Ensures feature consistency with training data.
    """
    df_processed = df_raw_input.copy()

    # Identify ORIGINAL categorical columns that were One-Hot Encoded during training
    # This list should match the original categorical columns in your raw training data
    original_categorical_cols = [
        'Education', 'Risk_Tolerance', 'Online_Platform_Usage_Freq', 'Bond_Credit_Rating'
        # Note: 'Age_Bin' is removed here as it was a feature-engineered category
    ]

    for col in original_categorical_cols:
        if col not in df_processed.columns:
            st.warning(f"Missing expected categorical column: '{col}'. Filling with default/NA.")
            df_processed[col] = pd.NA

    # Transform categorical features using the loaded encoder
    X_encoded = encoder.transform(df_processed[original_categorical_cols])
    X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(original_categorical_cols), index=df_processed.index)

    # Drop original categorical columns and concatenate encoded ones
    X_processed = pd.concat([df_processed.drop(columns=original_categorical_cols), X_encoded_df], axis=1)

    # IMPORTANT: Ensure feature consistency with the training data.
    # Add missing columns (features present in training but not in this new data), filled with zeros
    missing_in_new_data = list(set(trained_feature_names) - set(X_processed.columns))
    for col in missing_in_new_data:
        X_processed[col] = 0.0

    # Drop extra columns (features present in new data but not in training data)
    extra_in_new_data = list(set(X_processed.columns) - set(trained_feature_names))
    if extra_in_new_data:
        X_processed = X_processed.drop(columns=extra_in_new_data)

    # Ensure the order of columns is identical to training data
    X_processed = X_processed[trained_feature_names]

    return X_processed


# --- Streamlit App Layout ---
st.set_page_config(layout="wide")
st.title("ðŸ’° Bond Purchase Propensity Predictor (Manual Input)")
st.write("Enter customer and bond details to predict purchase likelihood.")

# --- Load Model and Encoder (Cached) ---
model, encoder, trained_feature_names = load_model_and_encoder()

# --- Input Form ---
st.header("Customer and Bond Details")

col1, col2, col3 = st.columns(3)

with col1:
    st.subheader("Customer Profile")
    age = st.slider("Age", 20, 80, 45)
    income = st.number_input("Annual Income (THB)", 10000, 5000000, 500000, step=10000)
    education = st.selectbox("Education Level", ['High School', 'Bachelors', 'Masters', 'PhD'])
    risk_tolerance = st.selectbox("Risk Tolerance", ['Conservative', 'Moderate', 'Aggressive'])

with col2:
    st.subheader("Customer Financials")
    existing_equity_holdings = st.number_input("Existing Equity Holdings (THB)", 0, 10000000, 1000000, step=100000)
    existing_bond_holdings = st.number_input("Existing Bond Holdings (THB)", 0, 20000000, 5000000, step=100000)
    num_other_products = st.slider("Number of Other Products Held", 0, 10, 2)
    last_investment_days_ago = st.slider("Days Since Last Investment", 1, 1000, 90)
    online_platform_usage_freq = st.selectbox("Online Platform Usage Frequency", ['Low', 'Medium', 'High'])

with col3:
    st.subheader("Bond Details (Group 3 Example)")
    bond_coupon_rate = st.slider("Bond Coupon Rate (%)", 0.01, 0.10, 0.035, step=0.001, format="%.3f")
    bond_maturity_years = st.slider("Bond Maturity (Years)", 1, 30, 10)
    bond_credit_rating = st.selectbox("Bond Credit Rating", ['AAA', 'AA', 'A', 'BBB'])
    bond_min_investment = st.number_input("Bond Minimum Investment (THB)", 10000, 5000000, 500000, step=10000)


if st.button("Predict Purchase Propensity"):
    # Create a single row DataFrame from user inputs
    input_data = pd.DataFrame([{
        'Customer_ID': 'Manual_Input_Customer',
        'Age': age,
        'Income': income,
        'Education': education,
        'Risk_Tolerance': risk_tolerance,
        'Existing_Equity_Holdings': existing_equity_holdings,
        'Existing_Bond_Holdings': existing_bond_holdings,
        # Re-include Total_AUM, Debt_to_Income_Ratio, Portfolio_Fixed_Income_Percent
        # if they were NOT derived during training but were original features.
        # If they were derived in training, you'd need the raw components here.
        'Total_AUM': income * np.random.uniform(1, 5) + existing_equity_holdings + existing_bond_holdings,
        'Num_Other_Products': num_other_products,
        'Last_Investment_Days_Ago': last_investment_days_ago,
        'Online_Platform_Usage_Freq': online_platform_usage_freq,
        'Bond_Coupon_Rate': bond_coupon_rate,
        'Bond_Maturity_Years': bond_maturity_years,
        'Bond_Credit_Rating': bond_credit_rating,
        'Bond_Min_Investment': bond_min_investment,
        'Debt_to_Income_Ratio': np.random.uniform(0.1, 0.8),
        'Portfolio_Fixed_Income_Percent': existing_bond_holdings / (income * np.random.uniform(1, 5) + existing_equity_holdings + existing_bond_holdings + 1e-6)
    }])

    # --- IMPORTANT: No feature engineering applied here as per your model's training ---
    # The input_data directly goes to preprocessing
    df_raw_for_preprocessing = input_data.drop('Customer_ID', axis=1) # Drop Customer_ID before preprocessing

    # Preprocess the data using the loaded encoder and trained features
    final_input_df = preprocess_for_prediction(df_raw_for_preprocessing, encoder, trained_feature_names)

    # Make prediction
    with st.spinner("Calculating propensity..."):
        prediction_proba = model.predict_proba(final_input_df)[:, 1][0]

    st.subheader("Prediction Result")
    if prediction_proba > 0.5:
        st.success(f"**High Potential Buyer!** Predicted Propensity: **{prediction_proba:.2%}**")
    else:
        st.info(f"Predicted Propensity: {prediction_proba:.2%}")
    st.write("*(Note: A higher percentage indicates a higher likelihood of purchasing this bond.)*")

    st.subheader("Input Data for Prediction (after preprocessing)")
    st.dataframe(final_input_df)


st.markdown("---")
st.markdown("Disclaimer: This is a simulated model for demonstration purposes only. Do not use for actual financial decisions.")